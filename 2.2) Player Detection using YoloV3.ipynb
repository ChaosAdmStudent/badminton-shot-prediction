{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd65022",
   "metadata": {},
   "source": [
    "Tracking Objects in Video with YOLOV3\n",
    "==============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea623285",
   "metadata": {},
   "source": [
    "Yolo is very fast (You Only Look Once) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bdaccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f22e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "BL = (195,654)\n",
    "BR = (1068,654)\n",
    "TR = (848,273)\n",
    "TL = (398,273) \n",
    "\n",
    "court_x, court_y = [data for data in zip(BL,BR,TR,TL)] \n",
    "\n",
    "start_x = min(court_x) \n",
    "range_x = max(court_x) - min(court_x) \n",
    "start_y = min(court_y) \n",
    "range_y = max(court_y) - min(court_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed2ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "PATH_WEIGHTS = os.path.abspath(os.path.join('YoloV3', 'yolov3.weights'))\n",
    "PATH_CFG = os.path.abspath(os.path.join('YoloV3', 'yolov3.cfg'))\n",
    "PATH_NAMES = os.path.join('YoloV3', 'coconames.txt') \n",
    "\n",
    "net = cv2.dnn.readNet(PATH_WEIGHTS, PATH_CFG)  \n",
    "classes = [] \n",
    "\n",
    "with open(PATH_NAMES, 'r') as f: \n",
    "    classes = f.read().splitlines()  \n",
    "    \n",
    "print(classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4d050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1280 \n",
    "height = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd48c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(filename):\n",
    "    video = cv2.VideoCapture(filename)\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            yield frame\n",
    "        else:\n",
    "            break\n",
    "    video.release()\n",
    "    yield None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa6a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Image to Blob for using Coco Model (Display blobs here) \n",
    "def getBlob(frame): \n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (416,416), (0,0,0), swapRB = True, crop=False) \n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34416e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerOutputs(blob): \n",
    "    net.setInput(blob) \n",
    "    output_layers_names = net.getUnconnectedOutLayersNames() \n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "    \n",
    "    return layerOutputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815c42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yoloPredict(layerOutputs): \n",
    "    boxes = [] \n",
    "    confidences = [] \n",
    "    class_ids = [] \n",
    "    \n",
    "    X_BUFFER = 0\n",
    "    Y_BUFFER = 70\n",
    "\n",
    "    for output in layerOutputs: \n",
    "        for detection in output: \n",
    "            scores = detection[5:]  # Scores of all the 80 classes (Starts from element 6)\n",
    "            class_id = np.argmax(scores)  \n",
    "            if not class_id == 0: # Only want person class\n",
    "                continue \n",
    "                \n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5: \n",
    "                center_x = int(detection[0] * width) \n",
    "                center_y = int(detection[1] * height) \n",
    "                if (start_x - X_BUFFER<= center_x <=start_x + range_x + X_BUFFER) and (start_y - Y_BUFFER<= center_y <=start_y + range_y + Y_BUFFER):\n",
    "                    w = int(detection[2] * width) \n",
    "                    h = int(detection[3] * height) \n",
    "\n",
    "                    x = int(center_x - w/2) # Doing this because OpenCV needs coordinate for corner to make rectangle\n",
    "                    y = int(center_y - h/2) # Same reason \n",
    "\n",
    "                    boxes.append([x,y,w,h])  \n",
    "                    confidences.append(float(confidence)) \n",
    "                    class_ids.append(class_id) \n",
    "                \n",
    "    return boxes, confidences, class_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14574bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayBoxes(frame, boxes , confidences , class_ids): \n",
    "    if len(boxes) == 0: \n",
    "        return False\n",
    "    \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)  # Unique boxes\n",
    "    font = cv2.FONT_HERSHEY_PLAIN \n",
    "    colors = np.random.uniform(0,255,size=(len(boxes), 3)) \n",
    "\n",
    "    for i in indexes.flatten():  \n",
    "        label = str(classes[class_ids[i]])  \n",
    "        x,y,w,h = boxes[i] \n",
    "        confidence = str(round(confidences[i],2)) \n",
    "        color = colors[i] \n",
    "\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), color, 2) \n",
    "        cv2.putText(frame, str(i) + ' ' + label + ' ' + confidence, (x,y+20), font, 2, (255,255,255), 2)\n",
    "    \n",
    "    cv2.imshow('frame', frame) \n",
    "    # 27 is the escape key. The number in the function is waiting time\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        if cv2.waitKey(0) == 27:\n",
    "            return True \n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47452a",
   "metadata": {},
   "source": [
    "#### Detecting Object in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c02123",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.path.join('data','train','10','frame1.jpg') \n",
    "img = cv2.imread(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a8e866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 1280\n"
     ]
    }
   ],
   "source": [
    "height, width, _ = img.shape \n",
    "print(height, width) \n",
    "\n",
    "# cv2.imshow('Image', img) \n",
    "# cv2.waitKey(0) \n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17119fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Image to Blob for using Coco Model (Display blobs here) \n",
    "\n",
    "blob = getBlob(img)  \n",
    "\n",
    "# for b in blob: \n",
    "#     for n, blob_img in enumerate(b): \n",
    "#         cv2.imshow(str(n), blob_img) \n",
    "\n",
    "# cv2.waitKey(0) \n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "569d7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "layerOutputs = getLayerOutputs(blob) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1575ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Predictions\n",
    "\n",
    "boxes , confidences , class_ids = yoloPredict(layerOutputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47b2ec96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[586, 159, 68, 148],\n",
       " [616, 314, 83, 197],\n",
       " [603, 312, 109, 199],\n",
       " [610, 322, 95, 191],\n",
       " [602, 317, 111, 199]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5548aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0]\n"
     ]
    }
   ],
   "source": [
    "# Getting rid of objects that had multiple bounding boxes made over it \n",
    "# Display indexes of only unique object bbox \n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4) \n",
    "print(indexes.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "498535c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display BBox on image \n",
    "\n",
    "displayBoxes(img, boxes,confidences, class_ids)  \n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b633e73",
   "metadata": {},
   "source": [
    "#### Detecting Objects in Video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7d13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VFILENAME = os.path.join('data', 'match2.mp4')\n",
    "\n",
    "for frame in get_frames(VFILENAME):\n",
    "    if frame is None: break \n",
    "        \n",
    "    blob = getBlob(frame)\n",
    "    layerOutputs = getLayerOutputs(blob) \n",
    "    boxes, confidences, class_ids = yoloPredict(layerOutputs) \n",
    "    terminate = displayBoxes(frame, boxes,confidences,class_ids) \n",
    "    if terminate: \n",
    "        break \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43ceb2",
   "metadata": {},
   "source": [
    "THINGS THAT CAN BE DONE \n",
    "\n",
    "\n",
    "1) Spread particles only within court space \n",
    "2) This is YOLO608. We can change the model to lower dimension \n",
    "3) We can also try YoloV5 \n",
    "\n",
    "4) Yolo => People detect \n",
    "   Particle Filter -> Color detect on Yolo detected people\n",
    "   \n",
    "5) Using shape + color difference for particle filter instead of color alone (Not sure how to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb365072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badminton",
   "language": "python",
   "name": "badminton"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
